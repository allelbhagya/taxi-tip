{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip_Distance_km</th>\n",
       "      <th>Time_of_Day</th>\n",
       "      <th>Day_of_Week</th>\n",
       "      <th>Passenger_Count</th>\n",
       "      <th>Traffic_Conditions</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Base_Fare</th>\n",
       "      <th>Per_Km_Rate</th>\n",
       "      <th>Per_Minute_Rate</th>\n",
       "      <th>Trip_Duration_Minutes</th>\n",
       "      <th>Trip_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.35</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Clear</td>\n",
       "      <td>3.56</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.32</td>\n",
       "      <td>53.82</td>\n",
       "      <td>36.2624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.59</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>1.0</td>\n",
       "      <td>High</td>\n",
       "      <td>Clear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.43</td>\n",
       "      <td>40.57</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.87</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>1.0</td>\n",
       "      <td>High</td>\n",
       "      <td>Clear</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.15</td>\n",
       "      <td>37.27</td>\n",
       "      <td>52.9032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.33</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.15</td>\n",
       "      <td>116.81</td>\n",
       "      <td>36.4698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>3.0</td>\n",
       "      <td>High</td>\n",
       "      <td>Clear</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.32</td>\n",
       "      <td>22.64</td>\n",
       "      <td>15.6180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Trip_Distance_km Time_of_Day Day_of_Week  Passenger_Count  \\\n",
       "0             19.35     Morning     Weekday              3.0   \n",
       "1             47.59   Afternoon     Weekday              1.0   \n",
       "2             36.87     Evening     Weekend              1.0   \n",
       "3             30.33     Evening     Weekday              4.0   \n",
       "4               NaN     Evening     Weekday              3.0   \n",
       "\n",
       "  Traffic_Conditions Weather  Base_Fare  Per_Km_Rate  Per_Minute_Rate  \\\n",
       "0                Low   Clear       3.56         0.80             0.32   \n",
       "1               High   Clear        NaN         0.62             0.43   \n",
       "2               High   Clear       2.70         1.21             0.15   \n",
       "3                Low     NaN       3.48         0.51             0.15   \n",
       "4               High   Clear       2.93         0.63             0.32   \n",
       "\n",
       "   Trip_Duration_Minutes  Trip_Price  \n",
       "0                  53.82     36.2624  \n",
       "1                  40.57         NaN  \n",
       "2                  37.27     52.9032  \n",
       "3                 116.81     36.4698  \n",
       "4                  22.64     15.6180  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('taxi_trip_pricing.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 11)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trip_Distance_km         0\n",
       "Time_of_Day              0\n",
       "Day_of_Week              0\n",
       "Passenger_Count          0\n",
       "Traffic_Conditions       0\n",
       "Weather                  0\n",
       "Base_Fare                0\n",
       "Per_Km_Rate              0\n",
       "Per_Minute_Rate          0\n",
       "Trip_Duration_Minutes    0\n",
       "Trip_Price               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(562, 11)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trip_Distance_km         float64\n",
       "Time_of_Day               object\n",
       "Day_of_Week               object\n",
       "Passenger_Count          float64\n",
       "Traffic_Conditions        object\n",
       "Weather                   object\n",
       "Base_Fare                float64\n",
       "Per_Km_Rate              float64\n",
       "Per_Minute_Rate          float64\n",
       "Trip_Duration_Minutes    float64\n",
       "Trip_Price               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhagya/Library/Python/3.9/lib/python/site-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/bhagya/Library/Python/3.9/lib/python/site-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(562, 11)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "\n",
    "oe = OrdinalEncoder()\n",
    "le = LabelEncoder()\n",
    "data['Time_of_Day'] = le.fit_transform(data['Time_of_Day'].values.reshape((-1,1)))\n",
    "data['Day_of_Week']  = le.fit_transform(data['Day_of_Week'].values.reshape((-1,1)))\n",
    "data['Traffic_Conditions'] = oe.fit_transform(data['Traffic_Conditions'].values.reshape((-1,1)))\n",
    "data['Weather'] = oe.fit_transform(data['Weather'].values.reshape((-1,1)))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip_Distance_km</th>\n",
       "      <th>Time_of_Day</th>\n",
       "      <th>Day_of_Week</th>\n",
       "      <th>Passenger_Count</th>\n",
       "      <th>Traffic_Conditions</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Base_Fare</th>\n",
       "      <th>Per_Km_Rate</th>\n",
       "      <th>Per_Minute_Rate</th>\n",
       "      <th>Trip_Duration_Minutes</th>\n",
       "      <th>Trip_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trip_Distance_km</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.013837</td>\n",
       "      <td>-0.052807</td>\n",
       "      <td>-0.034928</td>\n",
       "      <td>-0.106316</td>\n",
       "      <td>-0.018755</td>\n",
       "      <td>0.011602</td>\n",
       "      <td>0.009526</td>\n",
       "      <td>-0.051541</td>\n",
       "      <td>-0.012714</td>\n",
       "      <td>0.862965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time_of_Day</th>\n",
       "      <td>-0.013837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.014570</td>\n",
       "      <td>0.026880</td>\n",
       "      <td>-0.007814</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.084008</td>\n",
       "      <td>0.039006</td>\n",
       "      <td>-0.025430</td>\n",
       "      <td>0.016992</td>\n",
       "      <td>-0.002766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_of_Week</th>\n",
       "      <td>-0.052807</td>\n",
       "      <td>-0.014570</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008183</td>\n",
       "      <td>0.034473</td>\n",
       "      <td>0.041569</td>\n",
       "      <td>0.010148</td>\n",
       "      <td>-0.070712</td>\n",
       "      <td>-0.019182</td>\n",
       "      <td>-0.026843</td>\n",
       "      <td>-0.066792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Passenger_Count</th>\n",
       "      <td>-0.034928</td>\n",
       "      <td>0.026880</td>\n",
       "      <td>0.008183</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.053266</td>\n",
       "      <td>0.082952</td>\n",
       "      <td>0.109527</td>\n",
       "      <td>0.085722</td>\n",
       "      <td>0.043815</td>\n",
       "      <td>0.015793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traffic_Conditions</th>\n",
       "      <td>-0.106316</td>\n",
       "      <td>-0.007814</td>\n",
       "      <td>0.034473</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.073950</td>\n",
       "      <td>-0.021487</td>\n",
       "      <td>0.029847</td>\n",
       "      <td>0.002854</td>\n",
       "      <td>-0.002221</td>\n",
       "      <td>-0.109504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weather</th>\n",
       "      <td>-0.018755</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.041569</td>\n",
       "      <td>0.053266</td>\n",
       "      <td>0.073950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.056393</td>\n",
       "      <td>0.042454</td>\n",
       "      <td>-0.010524</td>\n",
       "      <td>0.086299</td>\n",
       "      <td>0.005860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base_Fare</th>\n",
       "      <td>0.011602</td>\n",
       "      <td>0.084008</td>\n",
       "      <td>0.010148</td>\n",
       "      <td>0.082952</td>\n",
       "      <td>-0.021487</td>\n",
       "      <td>-0.056393</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019944</td>\n",
       "      <td>-0.018082</td>\n",
       "      <td>0.055816</td>\n",
       "      <td>0.030897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Per_Km_Rate</th>\n",
       "      <td>0.009526</td>\n",
       "      <td>0.039006</td>\n",
       "      <td>-0.070712</td>\n",
       "      <td>0.109527</td>\n",
       "      <td>0.029847</td>\n",
       "      <td>0.042454</td>\n",
       "      <td>0.019944</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018978</td>\n",
       "      <td>0.077103</td>\n",
       "      <td>0.278268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Per_Minute_Rate</th>\n",
       "      <td>-0.051541</td>\n",
       "      <td>-0.025430</td>\n",
       "      <td>-0.019182</td>\n",
       "      <td>0.085722</td>\n",
       "      <td>0.002854</td>\n",
       "      <td>-0.010524</td>\n",
       "      <td>-0.018082</td>\n",
       "      <td>0.018978</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.018742</td>\n",
       "      <td>0.110967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trip_Duration_Minutes</th>\n",
       "      <td>-0.012714</td>\n",
       "      <td>0.016992</td>\n",
       "      <td>-0.026843</td>\n",
       "      <td>0.043815</td>\n",
       "      <td>-0.002221</td>\n",
       "      <td>0.086299</td>\n",
       "      <td>0.055816</td>\n",
       "      <td>0.077103</td>\n",
       "      <td>-0.018742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.221717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trip_Price</th>\n",
       "      <td>0.862965</td>\n",
       "      <td>-0.002766</td>\n",
       "      <td>-0.066792</td>\n",
       "      <td>0.015793</td>\n",
       "      <td>-0.109504</td>\n",
       "      <td>0.005860</td>\n",
       "      <td>0.030897</td>\n",
       "      <td>0.278268</td>\n",
       "      <td>0.110967</td>\n",
       "      <td>0.221717</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Trip_Distance_km  Time_of_Day  Day_of_Week  \\\n",
       "Trip_Distance_km               1.000000    -0.013837    -0.052807   \n",
       "Time_of_Day                   -0.013837     1.000000    -0.014570   \n",
       "Day_of_Week                   -0.052807    -0.014570     1.000000   \n",
       "Passenger_Count               -0.034928     0.026880     0.008183   \n",
       "Traffic_Conditions            -0.106316    -0.007814     0.034473   \n",
       "Weather                       -0.018755    -0.005159     0.041569   \n",
       "Base_Fare                      0.011602     0.084008     0.010148   \n",
       "Per_Km_Rate                    0.009526     0.039006    -0.070712   \n",
       "Per_Minute_Rate               -0.051541    -0.025430    -0.019182   \n",
       "Trip_Duration_Minutes         -0.012714     0.016992    -0.026843   \n",
       "Trip_Price                     0.862965    -0.002766    -0.066792   \n",
       "\n",
       "                       Passenger_Count  Traffic_Conditions   Weather  \\\n",
       "Trip_Distance_km             -0.034928           -0.106316 -0.018755   \n",
       "Time_of_Day                   0.026880           -0.007814 -0.005159   \n",
       "Day_of_Week                   0.008183            0.034473  0.041569   \n",
       "Passenger_Count               1.000000            0.001443  0.053266   \n",
       "Traffic_Conditions            0.001443            1.000000  0.073950   \n",
       "Weather                       0.053266            0.073950  1.000000   \n",
       "Base_Fare                     0.082952           -0.021487 -0.056393   \n",
       "Per_Km_Rate                   0.109527            0.029847  0.042454   \n",
       "Per_Minute_Rate               0.085722            0.002854 -0.010524   \n",
       "Trip_Duration_Minutes         0.043815           -0.002221  0.086299   \n",
       "Trip_Price                    0.015793           -0.109504  0.005860   \n",
       "\n",
       "                       Base_Fare  Per_Km_Rate  Per_Minute_Rate  \\\n",
       "Trip_Distance_km        0.011602     0.009526        -0.051541   \n",
       "Time_of_Day             0.084008     0.039006        -0.025430   \n",
       "Day_of_Week             0.010148    -0.070712        -0.019182   \n",
       "Passenger_Count         0.082952     0.109527         0.085722   \n",
       "Traffic_Conditions     -0.021487     0.029847         0.002854   \n",
       "Weather                -0.056393     0.042454        -0.010524   \n",
       "Base_Fare               1.000000     0.019944        -0.018082   \n",
       "Per_Km_Rate             0.019944     1.000000         0.018978   \n",
       "Per_Minute_Rate        -0.018082     0.018978         1.000000   \n",
       "Trip_Duration_Minutes   0.055816     0.077103        -0.018742   \n",
       "Trip_Price              0.030897     0.278268         0.110967   \n",
       "\n",
       "                       Trip_Duration_Minutes  Trip_Price  \n",
       "Trip_Distance_km                   -0.012714    0.862965  \n",
       "Time_of_Day                         0.016992   -0.002766  \n",
       "Day_of_Week                        -0.026843   -0.066792  \n",
       "Passenger_Count                     0.043815    0.015793  \n",
       "Traffic_Conditions                 -0.002221   -0.109504  \n",
       "Weather                             0.086299    0.005860  \n",
       "Base_Fare                           0.055816    0.030897  \n",
       "Per_Km_Rate                         0.077103    0.278268  \n",
       "Per_Minute_Rate                    -0.018742    0.110967  \n",
       "Trip_Duration_Minutes               1.000000    0.221717  \n",
       "Trip_Price                          0.221717    1.000000  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((562, 10), (562,))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop(['Trip_Price'], axis = 1)\n",
    "y = data['Trip_Price']\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((562, 10), (562, 1))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std = StandardScaler()\n",
    "X_scaled = std.fit_transform(X)\n",
    "y_scaled = std.fit_transform(y.values.reshape((-1,1)))\n",
    "X_scaled.shape, y_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhagya/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m132\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m13\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">145</span> (580.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m145\u001b[0m (580.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">145</span> (580.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m145\u001b[0m (580.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_shape = (X_train.shape[1],), activation = 'relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'sgd', metrics = ['mae', 'mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9094 - mae: 0.6199 - mse: 0.9094 - val_loss: 1.0297 - val_mae: 0.5535 - val_mse: 1.0297\n",
      "Epoch 2/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5307 - mae: 0.5228 - mse: 0.5307 - val_loss: 0.7250 - val_mae: 0.4805 - val_mse: 0.7250\n",
      "Epoch 3/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4217 - mae: 0.4706 - mse: 0.4217 - val_loss: 0.5583 - val_mae: 0.4293 - val_mse: 0.5583\n",
      "Epoch 4/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2948 - mae: 0.4180 - mse: 0.2948 - val_loss: 0.4497 - val_mae: 0.3944 - val_mse: 0.4497\n",
      "Epoch 5/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3008 - mae: 0.3872 - mse: 0.3008 - val_loss: 0.3784 - val_mae: 0.3656 - val_mse: 0.3784\n",
      "Epoch 6/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2358 - mae: 0.3512 - mse: 0.2358 - val_loss: 0.3174 - val_mae: 0.3504 - val_mse: 0.3174\n",
      "Epoch 7/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1943 - mae: 0.3205 - mse: 0.1943 - val_loss: 0.2840 - val_mae: 0.3343 - val_mse: 0.2840\n",
      "Epoch 8/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1723 - mae: 0.3008 - mse: 0.1723 - val_loss: 0.2595 - val_mae: 0.3223 - val_mse: 0.2595\n",
      "Epoch 9/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1225 - mae: 0.2621 - mse: 0.1225 - val_loss: 0.2414 - val_mae: 0.3152 - val_mse: 0.2414\n",
      "Epoch 10/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1581 - mae: 0.2838 - mse: 0.1581 - val_loss: 0.2293 - val_mae: 0.3089 - val_mse: 0.2293\n",
      "Epoch 11/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1428 - mae: 0.2661 - mse: 0.1428 - val_loss: 0.2163 - val_mae: 0.3037 - val_mse: 0.2163\n",
      "Epoch 12/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1104 - mae: 0.2430 - mse: 0.1104 - val_loss: 0.2082 - val_mae: 0.2986 - val_mse: 0.2082\n",
      "Epoch 13/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1005 - mae: 0.2400 - mse: 0.1005 - val_loss: 0.1990 - val_mae: 0.2954 - val_mse: 0.1990\n",
      "Epoch 14/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0916 - mae: 0.2285 - mse: 0.0916 - val_loss: 0.1926 - val_mae: 0.2930 - val_mse: 0.1926\n",
      "Epoch 15/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0923 - mae: 0.2283 - mse: 0.0923 - val_loss: 0.1863 - val_mae: 0.2906 - val_mse: 0.1863\n",
      "Epoch 16/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0868 - mae: 0.2302 - mse: 0.0868 - val_loss: 0.1814 - val_mae: 0.2883 - val_mse: 0.1814\n",
      "Epoch 17/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0934 - mae: 0.2200 - mse: 0.0934 - val_loss: 0.1799 - val_mae: 0.2842 - val_mse: 0.1799\n",
      "Epoch 18/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0974 - mae: 0.2284 - mse: 0.0974 - val_loss: 0.1761 - val_mae: 0.2816 - val_mse: 0.1761\n",
      "Epoch 19/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0836 - mae: 0.2198 - mse: 0.0836 - val_loss: 0.1724 - val_mae: 0.2799 - val_mse: 0.1724\n",
      "Epoch 20/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0847 - mae: 0.2164 - mse: 0.0847 - val_loss: 0.1738 - val_mae: 0.2766 - val_mse: 0.1738\n",
      "Epoch 21/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0876 - mae: 0.2082 - mse: 0.0876 - val_loss: 0.1720 - val_mae: 0.2730 - val_mse: 0.1720\n",
      "Epoch 22/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0816 - mae: 0.2090 - mse: 0.0816 - val_loss: 0.1682 - val_mae: 0.2716 - val_mse: 0.1682\n",
      "Epoch 23/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0832 - mae: 0.2134 - mse: 0.0832 - val_loss: 0.1669 - val_mae: 0.2682 - val_mse: 0.1669\n",
      "Epoch 24/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0668 - mae: 0.2043 - mse: 0.0668 - val_loss: 0.1618 - val_mae: 0.2671 - val_mse: 0.1618\n",
      "Epoch 25/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0863 - mae: 0.2116 - mse: 0.0863 - val_loss: 0.1615 - val_mae: 0.2648 - val_mse: 0.1615\n",
      "Epoch 26/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0675 - mae: 0.1983 - mse: 0.0675 - val_loss: 0.1578 - val_mae: 0.2635 - val_mse: 0.1578\n",
      "Epoch 27/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0767 - mae: 0.2111 - mse: 0.0767 - val_loss: 0.1558 - val_mae: 0.2622 - val_mse: 0.1558\n",
      "Epoch 28/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0653 - mae: 0.2008 - mse: 0.0653 - val_loss: 0.1530 - val_mae: 0.2610 - val_mse: 0.1530\n",
      "Epoch 29/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0795 - mae: 0.2076 - mse: 0.0795 - val_loss: 0.1569 - val_mae: 0.2580 - val_mse: 0.1569\n",
      "Epoch 30/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0815 - mae: 0.2060 - mse: 0.0815 - val_loss: 0.1548 - val_mae: 0.2566 - val_mse: 0.1548\n",
      "Epoch 31/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0639 - mae: 0.1895 - mse: 0.0639 - val_loss: 0.1522 - val_mae: 0.2554 - val_mse: 0.1522\n",
      "Epoch 32/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0700 - mae: 0.1954 - mse: 0.0700 - val_loss: 0.1500 - val_mae: 0.2543 - val_mse: 0.1500\n",
      "Epoch 33/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0776 - mae: 0.2025 - mse: 0.0776 - val_loss: 0.1490 - val_mae: 0.2528 - val_mse: 0.1490\n",
      "Epoch 34/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0746 - mae: 0.1962 - mse: 0.0746 - val_loss: 0.1495 - val_mae: 0.2518 - val_mse: 0.1495\n",
      "Epoch 35/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0877 - mae: 0.2087 - mse: 0.0877 - val_loss: 0.1478 - val_mae: 0.2506 - val_mse: 0.1478\n",
      "Epoch 36/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0547 - mae: 0.1852 - mse: 0.0547 - val_loss: 0.1458 - val_mae: 0.2497 - val_mse: 0.1458\n",
      "Epoch 37/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0688 - mae: 0.1916 - mse: 0.0688 - val_loss: 0.1446 - val_mae: 0.2487 - val_mse: 0.1446\n",
      "Epoch 38/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0672 - mae: 0.1945 - mse: 0.0672 - val_loss: 0.1444 - val_mae: 0.2478 - val_mse: 0.1444\n",
      "Epoch 39/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0776 - mae: 0.2036 - mse: 0.0776 - val_loss: 0.1433 - val_mae: 0.2470 - val_mse: 0.1433\n",
      "Epoch 40/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0796 - mae: 0.1969 - mse: 0.0796 - val_loss: 0.1440 - val_mae: 0.2452 - val_mse: 0.1440\n",
      "Epoch 41/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0562 - mae: 0.1805 - mse: 0.0562 - val_loss: 0.1437 - val_mae: 0.2443 - val_mse: 0.1437\n",
      "Epoch 42/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0648 - mae: 0.1917 - mse: 0.0648 - val_loss: 0.1417 - val_mae: 0.2432 - val_mse: 0.1417\n",
      "Epoch 43/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0659 - mae: 0.1841 - mse: 0.0659 - val_loss: 0.1404 - val_mae: 0.2423 - val_mse: 0.1404\n",
      "Epoch 44/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0667 - mae: 0.1864 - mse: 0.0667 - val_loss: 0.1393 - val_mae: 0.2410 - val_mse: 0.1393\n",
      "Epoch 45/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0663 - mae: 0.1799 - mse: 0.0663 - val_loss: 0.1388 - val_mae: 0.2403 - val_mse: 0.1388\n",
      "Epoch 46/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0587 - mae: 0.1823 - mse: 0.0587 - val_loss: 0.1322 - val_mae: 0.2414 - val_mse: 0.1322\n",
      "Epoch 47/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0703 - mae: 0.1929 - mse: 0.0703 - val_loss: 0.1338 - val_mae: 0.2394 - val_mse: 0.1338\n",
      "Epoch 48/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0556 - mae: 0.1788 - mse: 0.0556 - val_loss: 0.1337 - val_mae: 0.2379 - val_mse: 0.1337\n",
      "Epoch 49/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0536 - mae: 0.1763 - mse: 0.0536 - val_loss: 0.1326 - val_mae: 0.2372 - val_mse: 0.1326\n",
      "Epoch 50/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0455 - mae: 0.1658 - mse: 0.0455 - val_loss: 0.1314 - val_mae: 0.2360 - val_mse: 0.1314\n",
      "Epoch 51/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0638 - mae: 0.1863 - mse: 0.0638 - val_loss: 0.1317 - val_mae: 0.2346 - val_mse: 0.1317\n",
      "Epoch 52/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0503 - mae: 0.1720 - mse: 0.0503 - val_loss: 0.1234 - val_mae: 0.2401 - val_mse: 0.1234\n",
      "Epoch 53/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0651 - mae: 0.1825 - mse: 0.0651 - val_loss: 0.1228 - val_mae: 0.2374 - val_mse: 0.1228\n",
      "Epoch 54/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0679 - mae: 0.1863 - mse: 0.0679 - val_loss: 0.1280 - val_mae: 0.2330 - val_mse: 0.1280\n",
      "Epoch 55/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0467 - mae: 0.1709 - mse: 0.0467 - val_loss: 0.1272 - val_mae: 0.2316 - val_mse: 0.1272\n",
      "Epoch 56/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0532 - mae: 0.1724 - mse: 0.0532 - val_loss: 0.1281 - val_mae: 0.2301 - val_mse: 0.1281\n",
      "Epoch 57/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0667 - mae: 0.1892 - mse: 0.0667 - val_loss: 0.1274 - val_mae: 0.2295 - val_mse: 0.1274\n",
      "Epoch 58/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0666 - mae: 0.1797 - mse: 0.0666 - val_loss: 0.1269 - val_mae: 0.2286 - val_mse: 0.1269\n",
      "Epoch 59/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0625 - mae: 0.1792 - mse: 0.0625 - val_loss: 0.1274 - val_mae: 0.2273 - val_mse: 0.1274\n",
      "Epoch 60/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0450 - mae: 0.1652 - mse: 0.0450 - val_loss: 0.1258 - val_mae: 0.2270 - val_mse: 0.1258\n",
      "Epoch 61/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0555 - mae: 0.1680 - mse: 0.0555 - val_loss: 0.1267 - val_mae: 0.2258 - val_mse: 0.1267\n",
      "Epoch 62/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0593 - mae: 0.1747 - mse: 0.0593 - val_loss: 0.1293 - val_mae: 0.2238 - val_mse: 0.1293\n",
      "Epoch 63/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0471 - mae: 0.1594 - mse: 0.0471 - val_loss: 0.1261 - val_mae: 0.2236 - val_mse: 0.1261\n",
      "Epoch 64/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0662 - mae: 0.1772 - mse: 0.0662 - val_loss: 0.1262 - val_mae: 0.2226 - val_mse: 0.1262\n",
      "Epoch 65/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0421 - mae: 0.1589 - mse: 0.0421 - val_loss: 0.1254 - val_mae: 0.2221 - val_mse: 0.1254\n",
      "Epoch 66/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0404 - mae: 0.1556 - mse: 0.0404 - val_loss: 0.1246 - val_mae: 0.2221 - val_mse: 0.1246\n",
      "Epoch 67/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0459 - mae: 0.1610 - mse: 0.0459 - val_loss: 0.1324 - val_mae: 0.2209 - val_mse: 0.1324\n",
      "Epoch 68/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0567 - mae: 0.1637 - mse: 0.0567 - val_loss: 0.1277 - val_mae: 0.2202 - val_mse: 0.1277\n",
      "Epoch 69/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0478 - mae: 0.1652 - mse: 0.0478 - val_loss: 0.1256 - val_mae: 0.2197 - val_mse: 0.1256\n",
      "Epoch 70/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0502 - mae: 0.1699 - mse: 0.0502 - val_loss: 0.1241 - val_mae: 0.2190 - val_mse: 0.1241\n",
      "Epoch 71/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0486 - mae: 0.1651 - mse: 0.0486 - val_loss: 0.1278 - val_mae: 0.2177 - val_mse: 0.1278\n",
      "Epoch 72/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0748 - mae: 0.1786 - mse: 0.0748 - val_loss: 0.1264 - val_mae: 0.2171 - val_mse: 0.1264\n",
      "Epoch 73/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0416 - mae: 0.1546 - mse: 0.0416 - val_loss: 0.1230 - val_mae: 0.2170 - val_mse: 0.1230\n",
      "Epoch 74/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0531 - mae: 0.1709 - mse: 0.0531 - val_loss: 0.1201 - val_mae: 0.2171 - val_mse: 0.1201\n",
      "Epoch 75/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0451 - mae: 0.1576 - mse: 0.0451 - val_loss: 0.1192 - val_mae: 0.2168 - val_mse: 0.1192\n",
      "Epoch 76/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0539 - mae: 0.1632 - mse: 0.0539 - val_loss: 0.1203 - val_mae: 0.2154 - val_mse: 0.1203\n",
      "Epoch 77/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0386 - mae: 0.1514 - mse: 0.0386 - val_loss: 0.1192 - val_mae: 0.2153 - val_mse: 0.1192\n",
      "Epoch 78/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0487 - mae: 0.1542 - mse: 0.0487 - val_loss: 0.1200 - val_mae: 0.2146 - val_mse: 0.1200\n",
      "Epoch 79/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0498 - mae: 0.1632 - mse: 0.0498 - val_loss: 0.1199 - val_mae: 0.2140 - val_mse: 0.1199\n",
      "Epoch 80/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0478 - mae: 0.1611 - mse: 0.0478 - val_loss: 0.1194 - val_mae: 0.2134 - val_mse: 0.1194\n",
      "Epoch 81/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0468 - mae: 0.1595 - mse: 0.0468 - val_loss: 0.1188 - val_mae: 0.2129 - val_mse: 0.1188\n",
      "Epoch 82/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0417 - mae: 0.1545 - mse: 0.0417 - val_loss: 0.1189 - val_mae: 0.2118 - val_mse: 0.1189\n",
      "Epoch 83/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0428 - mae: 0.1590 - mse: 0.0428 - val_loss: 0.1182 - val_mae: 0.2111 - val_mse: 0.1182\n",
      "Epoch 84/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0424 - mae: 0.1518 - mse: 0.0424 - val_loss: 0.1178 - val_mae: 0.2107 - val_mse: 0.1178\n",
      "Epoch 85/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0462 - mae: 0.1556 - mse: 0.0462 - val_loss: 0.1176 - val_mae: 0.2100 - val_mse: 0.1176\n",
      "Epoch 86/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0374 - mae: 0.1505 - mse: 0.0374 - val_loss: 0.1158 - val_mae: 0.2105 - val_mse: 0.1158\n",
      "Epoch 87/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0403 - mae: 0.1476 - mse: 0.0403 - val_loss: 0.1164 - val_mae: 0.2097 - val_mse: 0.1164\n",
      "Epoch 88/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0675 - mae: 0.1741 - mse: 0.0675 - val_loss: 0.1182 - val_mae: 0.2082 - val_mse: 0.1182\n",
      "Epoch 89/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0490 - mae: 0.1581 - mse: 0.0490 - val_loss: 0.1170 - val_mae: 0.2076 - val_mse: 0.1170\n",
      "Epoch 90/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0499 - mae: 0.1556 - mse: 0.0499 - val_loss: 0.1174 - val_mae: 0.2066 - val_mse: 0.1174\n",
      "Epoch 91/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0572 - mae: 0.1556 - mse: 0.0572 - val_loss: 0.1167 - val_mae: 0.2061 - val_mse: 0.1167\n",
      "Epoch 92/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0413 - mae: 0.1590 - mse: 0.0413 - val_loss: 0.1144 - val_mae: 0.2065 - val_mse: 0.1144\n",
      "Epoch 93/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0459 - mae: 0.1597 - mse: 0.0459 - val_loss: 0.1151 - val_mae: 0.2058 - val_mse: 0.1151\n",
      "Epoch 94/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0590 - mae: 0.1597 - mse: 0.0590 - val_loss: 0.1170 - val_mae: 0.2053 - val_mse: 0.1170\n",
      "Epoch 95/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0379 - mae: 0.1425 - mse: 0.0379 - val_loss: 0.1159 - val_mae: 0.2046 - val_mse: 0.1159\n",
      "Epoch 96/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0370 - mae: 0.1471 - mse: 0.0370 - val_loss: 0.1107 - val_mae: 0.2062 - val_mse: 0.1107\n",
      "Epoch 97/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0482 - mae: 0.1549 - mse: 0.0482 - val_loss: 0.1122 - val_mae: 0.2049 - val_mse: 0.1122\n",
      "Epoch 98/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0336 - mae: 0.1438 - mse: 0.0336 - val_loss: 0.1116 - val_mae: 0.2047 - val_mse: 0.1116\n",
      "Epoch 99/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0378 - mae: 0.1442 - mse: 0.0378 - val_loss: 0.1124 - val_mae: 0.2039 - val_mse: 0.1124\n",
      "Epoch 100/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0372 - mae: 0.1457 - mse: 0.0372 - val_loss: 0.1114 - val_mae: 0.2039 - val_mse: 0.1114\n",
      "Epoch 101/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0411 - mae: 0.1509 - mse: 0.0411 - val_loss: 0.1121 - val_mae: 0.2035 - val_mse: 0.1121\n",
      "Epoch 102/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0418 - mae: 0.1514 - mse: 0.0418 - val_loss: 0.1115 - val_mae: 0.2032 - val_mse: 0.1115\n",
      "Epoch 103/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0432 - mae: 0.1545 - mse: 0.0432 - val_loss: 0.1112 - val_mae: 0.2028 - val_mse: 0.1112\n",
      "Epoch 104/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0544 - mae: 0.1540 - mse: 0.0544 - val_loss: 0.1113 - val_mae: 0.2025 - val_mse: 0.1113\n",
      "Epoch 105/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0354 - mae: 0.1428 - mse: 0.0354 - val_loss: 0.1106 - val_mae: 0.2022 - val_mse: 0.1106\n",
      "Epoch 106/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0438 - mae: 0.1460 - mse: 0.0438 - val_loss: 0.1122 - val_mae: 0.2012 - val_mse: 0.1122\n",
      "Epoch 107/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0375 - mae: 0.1474 - mse: 0.0375 - val_loss: 0.1124 - val_mae: 0.2006 - val_mse: 0.1124\n",
      "Epoch 108/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0451 - mae: 0.1490 - mse: 0.0451 - val_loss: 0.1120 - val_mae: 0.2000 - val_mse: 0.1120\n",
      "Epoch 109/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0412 - mae: 0.1441 - mse: 0.0412 - val_loss: 0.1116 - val_mae: 0.1995 - val_mse: 0.1116\n",
      "Epoch 110/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0395 - mae: 0.1453 - mse: 0.0395 - val_loss: 0.1107 - val_mae: 0.1996 - val_mse: 0.1107\n",
      "Epoch 111/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0374 - mae: 0.1398 - mse: 0.0374 - val_loss: 0.1118 - val_mae: 0.1986 - val_mse: 0.1118\n",
      "Epoch 112/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0440 - mae: 0.1471 - mse: 0.0440 - val_loss: 0.1101 - val_mae: 0.1992 - val_mse: 0.1101\n",
      "Epoch 113/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0403 - mae: 0.1398 - mse: 0.0403 - val_loss: 0.1102 - val_mae: 0.1988 - val_mse: 0.1102\n",
      "Epoch 114/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0449 - mae: 0.1463 - mse: 0.0449 - val_loss: 0.1100 - val_mae: 0.1986 - val_mse: 0.1100\n",
      "Epoch 115/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0387 - mae: 0.1408 - mse: 0.0387 - val_loss: 0.1101 - val_mae: 0.1985 - val_mse: 0.1101\n",
      "Epoch 116/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0464 - mae: 0.1468 - mse: 0.0464 - val_loss: 0.1098 - val_mae: 0.1982 - val_mse: 0.1098\n",
      "Epoch 117/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0338 - mae: 0.1344 - mse: 0.0338 - val_loss: 0.1100 - val_mae: 0.1979 - val_mse: 0.1100\n",
      "Epoch 118/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0363 - mae: 0.1412 - mse: 0.0363 - val_loss: 0.1099 - val_mae: 0.1971 - val_mse: 0.1099\n",
      "Epoch 119/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0296 - mae: 0.1308 - mse: 0.0296 - val_loss: 0.1087 - val_mae: 0.1976 - val_mse: 0.1087\n",
      "Epoch 120/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0433 - mae: 0.1454 - mse: 0.0433 - val_loss: 0.1094 - val_mae: 0.1973 - val_mse: 0.1094\n",
      "Epoch 121/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0442 - mae: 0.1409 - mse: 0.0442 - val_loss: 0.1096 - val_mae: 0.1971 - val_mse: 0.1096\n",
      "Epoch 122/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0332 - mae: 0.1367 - mse: 0.0332 - val_loss: 0.1091 - val_mae: 0.1969 - val_mse: 0.1091\n",
      "Epoch 123/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0402 - mae: 0.1387 - mse: 0.0402 - val_loss: 0.1095 - val_mae: 0.1968 - val_mse: 0.1095\n",
      "Epoch 124/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0377 - mae: 0.1393 - mse: 0.0377 - val_loss: 0.1082 - val_mae: 0.1968 - val_mse: 0.1082\n",
      "Epoch 125/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0391 - mae: 0.1372 - mse: 0.0391 - val_loss: 0.1103 - val_mae: 0.1961 - val_mse: 0.1103\n",
      "Epoch 126/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0408 - mae: 0.1425 - mse: 0.0408 - val_loss: 0.1081 - val_mae: 0.1963 - val_mse: 0.1081\n",
      "Epoch 127/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1404 - mse: 0.0350 - val_loss: 0.1083 - val_mae: 0.1958 - val_mse: 0.1083\n",
      "Epoch 128/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0317 - mae: 0.1326 - mse: 0.0317 - val_loss: 0.1081 - val_mae: 0.1959 - val_mse: 0.1081\n",
      "Epoch 129/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0322 - mae: 0.1363 - mse: 0.0322 - val_loss: 0.1083 - val_mae: 0.1953 - val_mse: 0.1083\n",
      "Epoch 130/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0374 - mae: 0.1413 - mse: 0.0374 - val_loss: 0.1107 - val_mae: 0.1943 - val_mse: 0.1107\n",
      "Epoch 131/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0417 - mae: 0.1399 - mse: 0.0417 - val_loss: 0.1107 - val_mae: 0.1938 - val_mse: 0.1107\n",
      "Epoch 132/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0409 - mae: 0.1395 - mse: 0.0409 - val_loss: 0.1099 - val_mae: 0.1939 - val_mse: 0.1099\n",
      "Epoch 133/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0306 - mae: 0.1313 - mse: 0.0306 - val_loss: 0.1085 - val_mae: 0.1944 - val_mse: 0.1085\n",
      "Epoch 134/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0323 - mae: 0.1345 - mse: 0.0323 - val_loss: 0.1079 - val_mae: 0.1947 - val_mse: 0.1079\n",
      "Epoch 135/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0363 - mae: 0.1339 - mse: 0.0363 - val_loss: 0.1088 - val_mae: 0.1944 - val_mse: 0.1088\n",
      "Epoch 136/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0515 - mae: 0.1458 - mse: 0.0515 - val_loss: 0.1092 - val_mae: 0.1938 - val_mse: 0.1092\n",
      "Epoch 137/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0334 - mae: 0.1393 - mse: 0.0334 - val_loss: 0.0995 - val_mae: 0.1982 - val_mse: 0.0995\n",
      "Epoch 138/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0382 - mae: 0.1476 - mse: 0.0382 - val_loss: 0.1021 - val_mae: 0.1964 - val_mse: 0.1021\n",
      "Epoch 139/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0399 - mae: 0.1465 - mse: 0.0399 - val_loss: 0.1037 - val_mae: 0.1951 - val_mse: 0.1037\n",
      "Epoch 140/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0322 - mae: 0.1372 - mse: 0.0322 - val_loss: 0.1044 - val_mae: 0.1944 - val_mse: 0.1044\n",
      "Epoch 141/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1315 - mse: 0.0344 - val_loss: 0.1050 - val_mae: 0.1940 - val_mse: 0.1050\n",
      "Epoch 142/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0284 - mae: 0.1292 - mse: 0.0284 - val_loss: 0.1043 - val_mae: 0.1940 - val_mse: 0.1043\n",
      "Epoch 143/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mae: 0.1342 - mse: 0.0349 - val_loss: 0.1056 - val_mae: 0.1928 - val_mse: 0.1056\n",
      "Epoch 144/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0476 - mae: 0.1404 - mse: 0.0476 - val_loss: 0.1070 - val_mae: 0.1926 - val_mse: 0.1070\n",
      "Epoch 145/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0334 - mae: 0.1292 - mse: 0.0334 - val_loss: 0.1066 - val_mae: 0.1921 - val_mse: 0.1066\n",
      "Epoch 146/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1317 - mse: 0.0360 - val_loss: 0.1058 - val_mae: 0.1917 - val_mse: 0.1058\n",
      "Epoch 147/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0353 - mae: 0.1359 - mse: 0.0353 - val_loss: 0.1055 - val_mae: 0.1914 - val_mse: 0.1055\n",
      "Epoch 148/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0285 - mae: 0.1273 - mse: 0.0285 - val_loss: 0.1047 - val_mae: 0.1917 - val_mse: 0.1047\n",
      "Epoch 149/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0439 - mae: 0.1374 - mse: 0.0439 - val_loss: 0.1056 - val_mae: 0.1912 - val_mse: 0.1056\n",
      "Epoch 150/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0376 - mae: 0.1334 - mse: 0.0376 - val_loss: 0.1059 - val_mae: 0.1908 - val_mse: 0.1059\n",
      "Epoch 151/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0422 - mae: 0.1352 - mse: 0.0422 - val_loss: 0.1062 - val_mae: 0.1905 - val_mse: 0.1062\n",
      "Epoch 152/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0324 - mae: 0.1260 - mse: 0.0324 - val_loss: 0.1044 - val_mae: 0.1908 - val_mse: 0.1044\n",
      "Epoch 153/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0381 - mae: 0.1357 - mse: 0.0381 - val_loss: 0.1041 - val_mae: 0.1906 - val_mse: 0.1041\n",
      "Epoch 154/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0284 - mae: 0.1220 - mse: 0.0284 - val_loss: 0.1072 - val_mae: 0.1897 - val_mse: 0.1072\n",
      "Epoch 155/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0456 - mae: 0.1341 - mse: 0.0456 - val_loss: 0.1068 - val_mae: 0.1900 - val_mse: 0.1068\n",
      "Epoch 156/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0316 - mae: 0.1265 - mse: 0.0316 - val_loss: 0.1055 - val_mae: 0.1902 - val_mse: 0.1055\n",
      "Epoch 157/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1279 - mse: 0.0351 - val_loss: 0.1060 - val_mae: 0.1899 - val_mse: 0.1060\n",
      "Epoch 158/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - mae: 0.1343 - mse: 0.0371 - val_loss: 0.1056 - val_mae: 0.1899 - val_mse: 0.1056\n",
      "Epoch 159/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0311 - mae: 0.1307 - mse: 0.0311 - val_loss: 0.1044 - val_mae: 0.1899 - val_mse: 0.1044\n",
      "Epoch 160/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0298 - mae: 0.1279 - mse: 0.0298 - val_loss: 0.1036 - val_mae: 0.1903 - val_mse: 0.1036\n",
      "Epoch 161/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0460 - mae: 0.1371 - mse: 0.0460 - val_loss: 0.1046 - val_mae: 0.1896 - val_mse: 0.1046\n",
      "Epoch 162/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0392 - mae: 0.1363 - mse: 0.0392 - val_loss: 0.1111 - val_mae: 0.1892 - val_mse: 0.1111\n",
      "Epoch 163/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0325 - mae: 0.1282 - mse: 0.0325 - val_loss: 0.1069 - val_mae: 0.1894 - val_mse: 0.1069\n",
      "Epoch 164/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0355 - mae: 0.1311 - mse: 0.0355 - val_loss: 0.1049 - val_mae: 0.1895 - val_mse: 0.1049\n",
      "Epoch 165/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - mae: 0.1341 - mse: 0.0371 - val_loss: 0.1057 - val_mae: 0.1893 - val_mse: 0.1057\n",
      "Epoch 166/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0304 - mae: 0.1266 - mse: 0.0304 - val_loss: 0.1112 - val_mae: 0.1881 - val_mse: 0.1112\n",
      "Epoch 167/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0330 - mae: 0.1286 - mse: 0.0330 - val_loss: 0.1073 - val_mae: 0.1884 - val_mse: 0.1073\n",
      "Epoch 168/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0348 - mae: 0.1325 - mse: 0.0348 - val_loss: 0.1060 - val_mae: 0.1888 - val_mse: 0.1060\n",
      "Epoch 169/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0395 - mae: 0.1298 - mse: 0.0395 - val_loss: 0.1055 - val_mae: 0.1890 - val_mse: 0.1055\n",
      "Epoch 170/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0440 - mae: 0.1405 - mse: 0.0440 - val_loss: 0.1049 - val_mae: 0.1885 - val_mse: 0.1049\n",
      "Epoch 171/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0283 - mae: 0.1224 - mse: 0.0283 - val_loss: 0.1039 - val_mae: 0.1888 - val_mse: 0.1039\n",
      "Epoch 172/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0363 - mae: 0.1275 - mse: 0.0363 - val_loss: 0.1036 - val_mae: 0.1889 - val_mse: 0.1036\n",
      "Epoch 173/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0241 - mae: 0.1192 - mse: 0.0241 - val_loss: 0.0991 - val_mae: 0.1903 - val_mse: 0.0991\n",
      "Epoch 174/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0335 - mae: 0.1295 - mse: 0.0335 - val_loss: 0.1017 - val_mae: 0.1890 - val_mse: 0.1017\n",
      "Epoch 175/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0396 - mae: 0.1348 - mse: 0.0396 - val_loss: 0.1026 - val_mae: 0.1885 - val_mse: 0.1026\n",
      "Epoch 176/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0345 - mae: 0.1246 - mse: 0.0345 - val_loss: 0.1026 - val_mae: 0.1880 - val_mse: 0.1026\n",
      "Epoch 177/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0280 - mae: 0.1249 - mse: 0.0280 - val_loss: 0.1017 - val_mae: 0.1883 - val_mse: 0.1017\n",
      "Epoch 178/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0325 - mae: 0.1330 - mse: 0.0325 - val_loss: 0.1018 - val_mae: 0.1877 - val_mse: 0.1018\n",
      "Epoch 179/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0480 - mae: 0.1367 - mse: 0.0480 - val_loss: 0.1032 - val_mae: 0.1870 - val_mse: 0.1032\n",
      "Epoch 180/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0315 - mae: 0.1264 - mse: 0.0315 - val_loss: 0.1093 - val_mae: 0.1860 - val_mse: 0.1093\n",
      "Epoch 181/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0289 - mae: 0.1222 - mse: 0.0289 - val_loss: 0.1070 - val_mae: 0.1861 - val_mse: 0.1070\n",
      "Epoch 182/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0401 - mae: 0.1298 - mse: 0.0401 - val_loss: 0.1083 - val_mae: 0.1859 - val_mse: 0.1083\n",
      "Epoch 183/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0336 - mae: 0.1273 - mse: 0.0336 - val_loss: 0.1056 - val_mae: 0.1862 - val_mse: 0.1056\n",
      "Epoch 184/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0386 - mae: 0.1310 - mse: 0.0386 - val_loss: 0.1047 - val_mae: 0.1862 - val_mse: 0.1047\n",
      "Epoch 185/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0305 - mae: 0.1264 - mse: 0.0305 - val_loss: 0.1035 - val_mae: 0.1865 - val_mse: 0.1035\n",
      "Epoch 186/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0273 - mae: 0.1200 - mse: 0.0273 - val_loss: 0.1032 - val_mae: 0.1864 - val_mse: 0.1032\n",
      "Epoch 187/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0277 - mae: 0.1241 - mse: 0.0277 - val_loss: 0.1022 - val_mae: 0.1867 - val_mse: 0.1022\n",
      "Epoch 188/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0335 - mae: 0.1265 - mse: 0.0335 - val_loss: 0.1034 - val_mae: 0.1861 - val_mse: 0.1034\n",
      "Epoch 189/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0303 - mae: 0.1233 - mse: 0.0303 - val_loss: 0.0974 - val_mae: 0.1882 - val_mse: 0.0974\n",
      "Epoch 190/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0331 - mae: 0.1241 - mse: 0.0331 - val_loss: 0.0990 - val_mae: 0.1867 - val_mse: 0.0990\n",
      "Epoch 191/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0292 - mae: 0.1254 - mse: 0.0292 - val_loss: 0.0991 - val_mae: 0.1864 - val_mse: 0.0991\n",
      "Epoch 192/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0265 - mae: 0.1217 - mse: 0.0265 - val_loss: 0.0997 - val_mae: 0.1861 - val_mse: 0.0997\n",
      "Epoch 193/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0449 - mae: 0.1335 - mse: 0.0449 - val_loss: 0.1006 - val_mae: 0.1853 - val_mse: 0.1006\n",
      "Epoch 194/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0321 - mae: 0.1296 - mse: 0.0321 - val_loss: 0.1008 - val_mae: 0.1852 - val_mse: 0.1008\n",
      "Epoch 195/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0300 - mae: 0.1205 - mse: 0.0300 - val_loss: 0.1006 - val_mae: 0.1848 - val_mse: 0.1006\n",
      "Epoch 196/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0336 - mae: 0.1248 - mse: 0.0336 - val_loss: 0.1007 - val_mae: 0.1846 - val_mse: 0.1007\n",
      "Epoch 197/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0323 - mae: 0.1252 - mse: 0.0323 - val_loss: 0.1008 - val_mae: 0.1846 - val_mse: 0.1008\n",
      "Epoch 198/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0258 - mae: 0.1213 - mse: 0.0258 - val_loss: 0.0955 - val_mae: 0.1866 - val_mse: 0.0955\n",
      "Epoch 199/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0327 - mae: 0.1311 - mse: 0.0327 - val_loss: 0.0972 - val_mae: 0.1853 - val_mse: 0.0972\n",
      "Epoch 200/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0300 - mae: 0.1207 - mse: 0.0300 - val_loss: 0.0985 - val_mae: 0.1849 - val_mse: 0.0985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x30dd66a60>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_split=0.2, epochs = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9445953689218257"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "r2_score(y_test, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
